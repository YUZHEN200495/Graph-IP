import networkx as nx
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Dropout, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import categorical_crossentropy

# Create a small-scale graph
G = nx.Graph()
G.add_nodes_from([0, 1, 2, 3])
G.add_edges_from([(0, 1), (0, 2), (1, 2), (2, 3)])

# Build the adjacency matrix
adj_matrix = nx.to_numpy_array(G)

# Randomly generate node features
num_nodes = G.number_of_nodes()
num_features = 4
node_features = np.random.rand(num_nodes, num_features)

# Randomly generate node labels (for classification task)
num_classes = 2
node_labels = np.random.randint(num_classes, size=num_nodes)

# Create GCN model
def create_gcn_model(input_dim, num_classes):
    inputs = Input(shape=(input_dim,))
    x = Dropout(0.5)(inputs)
    x = Dense(16, activation='relu')(x)
    x = Dropout(0.5)(x)
    outputs = Dense(num_classes, activation='softmax')(x)
    model = Model(inputs=inputs, outputs=outputs)
    return model

model = create_gcn_model(num_features, num_classes)

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.01), loss=categorical_crossentropy, metrics=['accuracy'])

# Train the model
model.fit(node_features, tf.one_hot(node_labels, num_classes), epochs=50, verbose=0)

# Evaluate the model
loss, accuracy = model.evaluate(node_features, tf.one_hot(node_labels, num_classes))
print(f"Test Loss: {loss}, Test Accuracy: {accuracy}")

# Import the legacy version of Adam optimizer
from tensorflow.keras.optimizers.legacy import Adam

# Create GCN model again
def create_gcn_model(input_dim, num_classes):
    inputs = Input(shape=(input_dim,))
    x = Dropout(0.5)(inputs)
    x = Dense(16, activation='relu')(x)
    x = Dropout(0.5)(x)
    outputs = Dense(num_classes, activation='softmax')(x)
    model = Model(inputs=inputs, outputs=outputs)
    return model

model = create_gcn_model(num_features, num_classes)

# Use the legacy version of Adam optimizer
model.compile(optimizer=Adam(learning_rate=0.01), loss=categorical_crossentropy, metrics=['accuracy'])

# Train the model
model.fit(node_features, tf.one_hot(node_labels, num_classes), epochs=50, verbose=0)

# Evaluate the model again
loss, accuracy = model.evaluate(node_features, tf.one_hot(node_labels, num_classes))
print(f"Test Loss: {loss}, Test Accuracy: {accuracy}")
